---
title: "No_imputation_prepare_SEM"
author: "Ali Soufizadeh"
date: "09/04/2022"
output: html_document
---

```{r set seed}
set.seed(79)
```

```{r include=FALSE}
# Load packages
pacman::p_load(pacman, tidyverse, kableExtra, psych, lavaan, corrplot, performance, MVN, ICS,
               dplyr,matrixStats, semPlot, gridExtra,knitr, readxl, papaja, report, mice, VIM,
               rmarkdown, janitor)
```

```{r}
# save the excel file as a dataframe named "all_data"
raw_data <- read_excel("Coded_data.xlsx")
```

```{r}
# Change variable names
raw_data <- rename(raw_data,
                   "duration" = "Duration(Second)", # in seconds
                   "gender" = "Sex")

columns = c("id", "Platform", "consent","duration", "Age","gender", "Edu", "SES")
demographics <- subset(raw_data, select = columns) 
raw_data <- raw_data[ , ! names(raw_data) %in% columns]
raw_data <- cbind(demographics, raw_data)
```

# RAW Demographics summary
```{r summary raw data}
describe(raw_data)
```

# Exclusion crtieria
- Based on Troy et al's (2017) criteria
```{r}
# 1. exclude all who didn't complete the survey or had missing data
no_missing <- drop_na(raw_data)
```

```{r}
# 2. exclude participants with zero variance among their answers
no_zero_var <- no_missing[apply(no_missing[, -c(1:4)], 1, var) != 0, ]
```

```{r}
# 3. exclude participants who took less than 3 minutes (180 seconds) to complete the survey
clean_data <- no_zero_var %>% filter(duration >= 180)
```

```{r}
# Check for duplicates
sum(duplicated(clean_data))
```

```{r}
describe(clean_data)
```

# Missing data
```{r visualise missing after imputation}
mice_plot <- aggr(clean_data,numbers=TRUE, sortVars=TRUE,
                  labels=colnames(clean_data), cex.axis=1,
                  gap=1, ylab=c("Missing data","Pattern"))
```

# Outliers
**Outliers Mahalanobis**
- Degrees of freedom in this case is based on the nr of variables (columns)
- Detect outliers based on **unscored** data
```{r Mahalnobis} 
# Mahalanobis for unscored data
mahal <- mahalanobis(clean_data[ , -c(1:7)],
  colMeans(clean_data[ , -c(1:7)], na.rm=TRUE),
  cov(clean_data[ , -c(1:7)], use ="pairwise.complete.obs"))

cutoff <- qchisq(p = 1 - .001, #1 minus alpha
                 df = ncol(clean_data[ , -c(1:7)])) # number of columns

cutoff # mahalanobis cutoff score
```

```{r drop outliers based on MD}
# Drop all outliers detected based on *unscored* data
summary(mahal < cutoff) #notice the direction 
no_outlier <- subset(clean_data, mahal < cutoff)
```

# No outlier data summary
```{r summary no outlier}
describe(no_outlier)
```

```{r check for duplicates}
# Check for duplicates
sum(duplicated(no_outlier))
```

# Score data
- Prepare to score the data with no outliers
```{r MCQ sub-scales}
# Create MCQ subscale variable groups
mcq_pos <- c("MCQ1","MCQ7","MCQ10",
             "MCQ19","MCQ23","MCQ28")

mcq_neg <- c("MCQ2","MCQ4","MCQ9",
             "MCQ11","MCQ15","MCQ21")

mcq_cc <- c("MCQ8","MCQ14","MCQ17",
            "MCQ24","MCQ26","MCQ29")

mcq_nc <- c("MCQ6","MCQ13","MCQ20",
            "MCQ22","MCQ25","MCQ27")

mcq_csc <- c("MCQ3","MCQ5","MCQ12",
             "MCQ16","MCQ18","MCQ30")
```

```{r Function to score data}
# Function to Score data
function_score_data <-function(no_outlier){

#save variables in separate data frame
  scored_data <- no_outlier %>%
  
  #row mean of the selected columns
  mutate(across(c("PSS2", "PSS3"), ~{6 - .}), # recode PSS items 2 & 3 (6 - response)
         across(c("BSM1", "BSM3", "BSM7", "BSM8"), ~{8 - .}), # first recode BSM items 1, 3, 7, 8 (8 - response)
         mean_cra = rowMeans(select(., starts_with("CRA"))),
         mean_hcru = rowMeans(select(., starts_with("HCRU"))),
         mean_pss = rowMeans(select(., starts_with("PSS"))),
         
         mean_bsm = rowMeans(select(., starts_with("BSM"))),
         #for cesd, we need the sum
         sum_cesd = rowSums(select(., starts_with("CES_D"))),
         
         # sum all MCQ subscales
         sum_pos = rowSums(select(.,all_of(mcq_pos))),
         sum_neg = rowSums(select(.,all_of(mcq_neg))),
         sum_cc = rowSums(select(.,all_of(mcq_cc))),
         sum_nc = rowSums(select(.,all_of(mcq_nc))),
         sum_csc = rowSums(select(.,all_of(mcq_csc))),
         sum_MCQ = rowSums(select(.,starts_with("MCQ"))))%>%
  
  return(scored_data)
}
```

```{r Run Score data FUN}
scored_data <- function_score_data(no_outlier) # Score the data with no outliers
```

# Interaction terms
```{r}
scored_data <- read.csv("/Users/Pinocchio/R/Thesis_git_repository/Data_analysis/Data/C_scored.csv")
# Create interaction terms

scored_data <- scored_data %>% mutate(rename(scored_data,
                                      "X" = "mean_cra",
                                      "Y" = "sum_cesd",
                                      "W" = "SES",
                                      "Z" = "mean_bsm",
                                      "COV" = "mean_pss"))

scored_data <- scored_data %>% mutate(X.W = X * W,
                               X.Z = X * Z,
                               W.Z = W * Z,
                               X.W.Z = X * W * Z)
```


```{r Save data to csv, echo=TRUE}
write.csv(scored_data, "scored_data_SEM_no_imp.csv", row.names = FALSE) # Save scored data in a csv file
```

# Summary of cleaned data and scored data
```{r summary scored data}
describe(scored_data[,-c(8:69)]) # Missing Data & outliers checked
```

# Assumptions: Additivity
```{r correlation plot}
plot_data <- cbind(scored_data["SES"],scored_data[ , -c(1:69)])
corPlot(cor(plot_data), upper = F)
```

# Assumption: Multivariate Normality
```{r normality test}
mvntest_result <- mvn(scored_data[8:69], mvnTest = "hz")
mvntest_result$multivariateNormality
```
# Assumption: Kurtosis
```{r Kurtosis test}
mvnorm.kur.test(scored_data[8:69], method = "simulation")
```

# Assumption: Skewness
```{r Skewness test}
mvnorm.skew.test(scored_data[8:69])
```

# Frequency tables
```{r Gender}
# Gender
gender_freq <- scored_data %>% tabyl(gender)
levels(gender_freq$gender) <- c("male","female", "non-binary", "DWA")
apa_table(gender_freq, caption = "Proportions of Gender")
```

```{r Education}
# Education
edu_freq <- scored_data %>% tabyl(Edu)
levels(edu_freq$Edu) <- c("Elementary or lower","Highschool Diploma", "Bachelor's", "Master's", "PhD or higher")
apa_table(edu_freq, caption = "Proportions of Education level")
```

# Descriptives
- In the first step, the data are summarized to get the descriptive statistics.
- Subsequently, the data are reformatted.
```{r Descriptives}
descriptives <- scored_data %>% 
  dplyr::summarize(across(c(SES, Age, mean_cra, mean_hcru,sum_cesd, 
                            mean_pss, mean_bsm, sum_pos,sum_neg, 
                            sum_cc, sum_nc, sum_csc, sum_MCQ),
                          list(mean = mean, sd = sd, min = min, max = max))) %>%
  
  # bring everything in long format
  pivot_longer(everything(), names_to = "name") %>%
  
  # separate names at last underscore
  separate(name, into = c("name","descriptive"), sep = "_(?=[^_]+$)") %>%
  
  # get into a bit wider format again
  pivot_wider(names_from = name, values_from = value) %>%
  
  # rename to have nicer column names
  rename(Summary = descriptive,
         CRA = mean_cra,  #
         HCRU = mean_hcru, #
         PSS = mean_pss,  #
         CESD = sum_cesd, #
         BSM = mean_bsm,  #
         POS = sum_pos,  #
         NEG = sum_neg, # 
         CC = sum_cc, #
         NC = sum_nc, #
         CSC = sum_csc, #
         MCQT = sum_MCQ) # MCQ =Meta Cognitions Questionnaire Total
```

# Cronbach’s alphas
- Select the items from the *raw* or *un-scored* data that belong to the specific scale.
- calculate alpha and extract raw_alpha from the list the alpha function generates.
```{r Chronbacks alphas}
# Calculate cronbach’s alphas
alpha <- scored_data %>%
  dplyr::summarize(
    # Replication Block Alphas
    cra_alpha = select(.,starts_with("CRA")) %>% psych::alpha() %>%
      pluck("total", "raw_alpha"), # extract total and then raw_alpha from list
    hcru_alpha = select(.,starts_with("HCRU")) %>% psych::alpha() %>%
      pluck("total", "raw_alpha"),
    cesd_alpha = select(.,starts_with("CES_D")) %>% psych::alpha() %>%
      pluck("total", "raw_alpha"),
    pss_alpha = select(.,starts_with("PSS")) %>% psych::alpha(check.keys=TRUE) %>%
      pluck("total", "raw_alpha"),
    
    # BSM Alphas
    BSM_alpha = select(.,starts_with("BSM")) %>% psych::alpha(check.keys=TRUE) %>%
      pluck("total", "raw_alpha"),
    
    # MCQ scale Alphas
    pos_alpha = select(.,all_of(mcq_pos)) %>% psych::alpha() %>%
      pluck("total", "raw_alpha"),
    neg_alpha = select(.,all_of(mcq_neg)) %>% psych::alpha() %>%
      pluck("total", "raw_alpha"),
    cc_alpha = select(.,all_of(mcq_cc)) %>% psych::alpha() %>%
      pluck("total", "raw_alpha"),
    nc_alpha = select(.,all_of(mcq_nc)) %>% psych::alpha() %>%
      pluck("total", "raw_alpha"),
    csc_alpha = select(.,all_of(mcq_csc)) %>% psych::alpha() %>%
      pluck("total", "raw_alpha"),
    mcq_alpha = select(.,all_of(mcq_csc)) %>% psych::alpha() %>%
      pluck("total", "raw_alpha"))
```

```{r Descriptives2}
# add alphas as extra row to the descriptives table
descriptives <- descriptives %>%
  add_row(Summary = "alpha", SES = NA, CRA = alpha$cra_alpha, HCRU = alpha$hcru_alpha,
          PSS = alpha$pss_alpha, CESD = alpha$cesd_alpha, BSM = alpha$BSM_alpha, 
          POS = alpha$pos_alpha, NEG = alpha$neg_alpha, CC = alpha$cc_alpha,
          NC = alpha$nc_alpha, CSC = alpha$csc_alpha, MCQT = alpha$mcq_alpha)
```

# Descriptives table
```{r Descriptives table}
# Make a nicely formatted table
apa_table(descriptives) # is only shown when RMarkdown document is knitted
```

# Plot monthly family income
```{r income plot}
income_plot<-hist(scored_data$SES,
                  main="Family income distribution",
                  xlab="family income category")
```